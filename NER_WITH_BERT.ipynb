{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOcam7pE37gFYFHflIUvXDi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b85487cb3cbc4c1da822a0c036b8fdea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2cb94704cf66435b81ff24d2a8fb7b06",
              "IPY_MODEL_f19da5a9934a4603bb25ecc8baef6694",
              "IPY_MODEL_8d03c2eed255421c8f791d05fb99a688"
            ],
            "layout": "IPY_MODEL_9cc8553f85684cc784904ed5399d3322"
          }
        },
        "2cb94704cf66435b81ff24d2a8fb7b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c843dbafcfc4224b4a6adbc7a1dac33",
            "placeholder": "​",
            "style": "IPY_MODEL_85fd2ee8a6ed43118e85227db73a8c3b",
            "value": "Downloading builder script: "
          }
        },
        "f19da5a9934a4603bb25ecc8baef6694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee8c3e33b24e48dcbea2a9cb8051842b",
            "max": 2472,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92e463fd9c784f79bf09f07831e881fa",
            "value": 2472
          }
        },
        "8d03c2eed255421c8f791d05fb99a688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7aff299189e42ee8b0b43fcb0a7f85b",
            "placeholder": "​",
            "style": "IPY_MODEL_fa4f4f84a5f74d90b56176b407717540",
            "value": " 6.33k/? [00:00&lt;00:00, 234kB/s]"
          }
        },
        "9cc8553f85684cc784904ed5399d3322": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c843dbafcfc4224b4a6adbc7a1dac33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85fd2ee8a6ed43118e85227db73a8c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee8c3e33b24e48dcbea2a9cb8051842b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92e463fd9c784f79bf09f07831e881fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7aff299189e42ee8b0b43fcb0a7f85b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa4f4f84a5f74d90b56176b407717540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaibhavdangar09/NER-WITH-BERT/blob/main/NER_WITH_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Named entity recognition (NER): Find the entities (such as persons, locations, or organizations) in a sentence. This can be formulated as attributing a label to each token by having one class per entity and one class for “no entity.”\n",
        "\n",
        "Part-of-speech tagging (POS): Mark each word in a sentence as corresponding to a particular part of speech (such as noun, verb, adjective, etc.).\n",
        "\n",
        "Chunking: Find the tokens that belong to the same entity. This task (which can be combined with POS or NER) can be formulated as attributing one label (usually B-) to any tokens that are at the beginning of a chunk, another label (usually I-) to tokens that are inside a chunk, and a third label (usually O) to tokens that don’t belong to any chunk.\n",
        "\n",
        "O means the word doesn’t correspond to any entity.\n",
        "\n",
        "B-PER/I-PER means the word corresponds to the beginning of/is inside a person entity.\n",
        "\n",
        "B-ORG/I-ORG means the word corresponds to the beginning of/is inside an organization entity.\n",
        "\n",
        "B-LOC/I-LOC means the word corresponds to the beginning of/is inside a location entity.\n",
        "\n",
        "B-MISC/I-MISC means the word corresponds to the beginning of/is inside a miscellaneous entity."
      ],
      "metadata": {
        "id": "v1Rbw7cIu5us"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1LlK0DO6mh8u"
      },
      "outputs": [],
      "source": [
        "# install packages\n",
        "!pip install transformers datasets tokenizers seqeval -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Import Libraries**"
      ],
      "metadata": {
        "id": "lsKnxeh6w5Kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import numpy as np\n",
        "from transformers import BertTokenizerFast\n",
        "from transformers import DataCollatorForTokenClassification  # This libary apply augumentation technique at runtime\n",
        "from transformers import AutoModelForTokenClassification     # This class is responsible for load model into my memory"
      ],
      "metadata": {
        "id": "0C2hz-NfwyOe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load dataset**"
      ],
      "metadata": {
        "id": "HqK36jJP68IV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner_data = datasets.load_dataset(\"conll2003\")"
      ],
      "metadata": {
        "id": "R6RrHJipzTi1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Know Your Data**"
      ],
      "metadata": {
        "id": "DQvK0kpM-Q22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset information\n",
        "ner_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa9gKulI7H5q",
        "outputId": "53afaf4a-6dd7-40f7-832d-3b73db2168d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# structure of train data\n",
        "ner_data['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttS7ZYp87vTt",
        "outputId": "756ce568-1513-4d99-996a-75d4eb318523"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
              " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
              " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#structure of test data\n",
        "ner_data['test'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdMBHXd678Ae",
        "outputId": "3644b871-e152-4bb1-af27-6a4a73414b50"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['SOCCER',\n",
              "  '-',\n",
              "  'JAPAN',\n",
              "  'GET',\n",
              "  'LUCKY',\n",
              "  'WIN',\n",
              "  ',',\n",
              "  'CHINA',\n",
              "  'IN',\n",
              "  'SURPRISE',\n",
              "  'DEFEAT',\n",
              "  '.'],\n",
              " 'pos_tags': [21, 8, 22, 37, 22, 22, 6, 22, 15, 12, 21, 7],\n",
              " 'chunk_tags': [11, 0, 11, 21, 11, 12, 0, 11, 13, 11, 12, 0],\n",
              " 'ner_tags': [0, 0, 5, 0, 0, 0, 0, 1, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#structure of validaion data\n",
        "ner_data['validation'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH9wbwn08B_V",
        "outputId": "b698d713-9c57-4ad3-c49b-53fa524a9163"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['CRICKET',\n",
              "  '-',\n",
              "  'LEICESTERSHIRE',\n",
              "  'TAKE',\n",
              "  'OVER',\n",
              "  'AT',\n",
              "  'TOP',\n",
              "  'AFTER',\n",
              "  'INNINGS',\n",
              "  'VICTORY',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 8, 22, 22, 15, 22, 22, 22, 22, 21, 7],\n",
              " 'chunk_tags': [11, 0, 11, 12, 13, 11, 12, 12, 12, 12, 0],\n",
              " 'ner_tags': [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# name of the ner-tags\n",
        "ner_data['train'].features[\"ner_tags\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1eWI85q89bI",
        "outputId": "ace24cc7-829a-4bb2-ba9b-9aa2439c31f7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#description of the dataset\n",
        "ner_data['train'].description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "f58wMZ5R93iT",
        "outputId": "ff22f3bb-dfe0-4df6-8324-2b23d9caa436"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on\\nfour types of named entities: persons, locations, organizations and names of miscellaneous entities that do\\nnot belong to the previous three groups.\\n\\nThe CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on\\na separate line and there is an empty line after each sentence. The first item on each line is a word, the second\\na part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags\\nand the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only\\nif two phrases of the same type immediately follow each other, the first word of the second phrase will have tag\\nB-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Note the dataset uses IOB2\\ntagging scheme, whereas the original dataset uses IOB1.\\n\\nFor more details see https://www.clips.uantwerpen.be/conll2003/ner/ and https://www.aclweb.org/anthology/W03-0419\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hugging face bert-base-uncased model**"
      ],
      "metadata": {
        "id": "-F4vj_ns_Z8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# intializing tokenizer with help of bert model\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "C_CWVSBx_k-P"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k1B3sSADraf",
        "outputId": "57d33cf5-1252-4dd7-ccdd-3a167d000450"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = ner_data['train'][0]\n",
        "tokenized_input = tokenizer(example_text['tokens'],is_split_into_words=True)\n",
        "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
        "word_ids = tokenized_input.word_ids()"
      ],
      "metadata": {
        "id": "byS6jZEmCfaM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_input)\n",
        "print(\"\\n\")\n",
        "print(tokens)\n",
        "print(\"\\n\")\n",
        "print(word_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsS8a31SDuir",
        "outputId": "9cb9c494-878c-4481-faed-0db2ac900cc9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "\n",
            "\n",
            "['[CLS]', 'eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.', '[SEP]']\n",
            "\n",
            "\n",
            "[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Length of the tokens is : {len(tokens)}')\n",
        "print(f'Length of the ner tags is: {len(ner_data[\"train\"][0][\"ner_tags\"])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDZHl0xhk9Qc",
        "outputId": "91c1115d-d8ed-459f-ca1c-1154171bce00"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the tokens is : 11\n",
            "Length of the ner tags is: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Here the dimensions of the ner tags and tokens are different , so to make same dimensions of tokens and ner tags we add -100 at the first and last position of the ner tags.\n",
        "\n",
        "* During training , BERT model avoid the -100."
      ],
      "metadata": {
        "id": "XYC5S4khnmfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples, label_all_tokens=True):\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        # word_ids() => Return a list mapping the tokens\n",
        "        # to their actual word in the initial sentence.\n",
        "        # It Returns a list indicating the word corresponding to each token.\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        # Special tokens like `` and `<\\s>` are originally mapped to None\n",
        "        # We need to set the label to -100 so they are automatically ignored in the loss function.\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                # set –100 as the label for these special tokens\n",
        "                label_ids.append(-100)\n",
        "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
        "            # the label_all_tokens flag.\n",
        "            elif word_idx != previous_word_idx:\n",
        "                # if current word_idx is != prev then its the most regular case\n",
        "                # and add the corresponding token\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                # to take care of sub-words which have the same word_idx\n",
        "                # set -100 as well for them, but only if label_all_tokens == False\n",
        "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
        "                # mask the subword representations after the first subword\n",
        "\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs"
      ],
      "metadata": {
        "id": "CHZV9jPE676V"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_data['train'][4:5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rynLUil9nnk",
        "outputId": "862da837-f2db-4be3-ab77-bb669f46b345"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': ['4'],\n",
              " 'tokens': [['Germany',\n",
              "   \"'s\",\n",
              "   'representative',\n",
              "   'to',\n",
              "   'the',\n",
              "   'European',\n",
              "   'Union',\n",
              "   \"'s\",\n",
              "   'veterinary',\n",
              "   'committee',\n",
              "   'Werner',\n",
              "   'Zwingmann',\n",
              "   'said',\n",
              "   'on',\n",
              "   'Wednesday',\n",
              "   'consumers',\n",
              "   'should',\n",
              "   'buy',\n",
              "   'sheepmeat',\n",
              "   'from',\n",
              "   'countries',\n",
              "   'other',\n",
              "   'than',\n",
              "   'Britain',\n",
              "   'until',\n",
              "   'the',\n",
              "   'scientific',\n",
              "   'advice',\n",
              "   'was',\n",
              "   'clearer',\n",
              "   '.']],\n",
              " 'pos_tags': [[22,\n",
              "   27,\n",
              "   21,\n",
              "   35,\n",
              "   12,\n",
              "   22,\n",
              "   22,\n",
              "   27,\n",
              "   16,\n",
              "   21,\n",
              "   22,\n",
              "   22,\n",
              "   38,\n",
              "   15,\n",
              "   22,\n",
              "   24,\n",
              "   20,\n",
              "   37,\n",
              "   21,\n",
              "   15,\n",
              "   24,\n",
              "   16,\n",
              "   15,\n",
              "   22,\n",
              "   15,\n",
              "   12,\n",
              "   16,\n",
              "   21,\n",
              "   38,\n",
              "   17,\n",
              "   7]],\n",
              " 'chunk_tags': [[11,\n",
              "   11,\n",
              "   12,\n",
              "   13,\n",
              "   11,\n",
              "   12,\n",
              "   12,\n",
              "   11,\n",
              "   12,\n",
              "   12,\n",
              "   12,\n",
              "   12,\n",
              "   21,\n",
              "   13,\n",
              "   11,\n",
              "   12,\n",
              "   21,\n",
              "   22,\n",
              "   11,\n",
              "   13,\n",
              "   11,\n",
              "   1,\n",
              "   13,\n",
              "   11,\n",
              "   17,\n",
              "   11,\n",
              "   12,\n",
              "   12,\n",
              "   21,\n",
              "   1,\n",
              "   0]],\n",
              " 'ner_tags': [[5,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   3,\n",
              "   4,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   2,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   5,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0]]}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = tokenize_and_align_labels(ner_data['train'][4:5])\n",
        "print(q)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MydrcSiI84lu",
        "outputId": "06e06ec0-6bf4-4442-91f2-15724fecaef3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 2762, 1005, 1055, 4387, 2000, 1996, 2647, 2586, 1005, 1055, 15651, 2837, 14121, 1062, 9328, 5804, 2056, 2006, 9317, 10390, 2323, 4965, 8351, 4168, 4017, 2013, 3032, 2060, 2084, 3725, 2127, 1996, 4045, 6040, 2001, 24509, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, -100]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So before applying the tokenize_and_align_labels() the tokenized_input has 3 keys\n",
        "\n",
        "* input_ids\n",
        "* token_type_ids\n",
        "* attention_mask\n",
        "\n",
        "But after applying tokenize_and_align_labels() we have an extra key - 'labels'"
      ],
      "metadata": {
        "id": "GI_JN_8zHGGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token, label in zip(tokenizer.convert_ids_to_tokens(q[\"input_ids\"][0]),q[\"labels\"][0]):\n",
        "    print(f\"{token:_<40} {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1zIT2clDYIF",
        "outputId": "459115f2-2053-4d34-fc37-175c4db28b13"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]___________________________________ -100\n",
            "germany_________________________________ 5\n",
            "'_______________________________________ 0\n",
            "s_______________________________________ 0\n",
            "representative__________________________ 0\n",
            "to______________________________________ 0\n",
            "the_____________________________________ 0\n",
            "european________________________________ 3\n",
            "union___________________________________ 4\n",
            "'_______________________________________ 0\n",
            "s_______________________________________ 0\n",
            "veterinary______________________________ 0\n",
            "committee_______________________________ 0\n",
            "werner__________________________________ 1\n",
            "z_______________________________________ 2\n",
            "##wing__________________________________ 2\n",
            "##mann__________________________________ 2\n",
            "said____________________________________ 0\n",
            "on______________________________________ 0\n",
            "wednesday_______________________________ 0\n",
            "consumers_______________________________ 0\n",
            "should__________________________________ 0\n",
            "buy_____________________________________ 0\n",
            "sheep___________________________________ 0\n",
            "##me____________________________________ 0\n",
            "##at____________________________________ 0\n",
            "from____________________________________ 0\n",
            "countries_______________________________ 0\n",
            "other___________________________________ 0\n",
            "than____________________________________ 0\n",
            "britain_________________________________ 5\n",
            "until___________________________________ 0\n",
            "the_____________________________________ 0\n",
            "scientific______________________________ 0\n",
            "advice__________________________________ 0\n",
            "was_____________________________________ 0\n",
            "clearer_________________________________ 0\n",
            "._______________________________________ 0\n",
            "[SEP]___________________________________ -100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Applying on entire data\n",
        "tokenized_datasets = ner_data.map(tokenize_and_align_labels, batched=True)\n"
      ],
      "metadata": {
        "id": "Rep2O2V2Hvqu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMgL_9oHH4dO",
        "outputId": "a3541c34-a8e8-4077-eb61-9d11187be7ab"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
              " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
              " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0],\n",
              " 'input_ids': [101,\n",
              "  7327,\n",
              "  19164,\n",
              "  2446,\n",
              "  2655,\n",
              "  2000,\n",
              "  17757,\n",
              "  2329,\n",
              "  12559,\n",
              "  1012,\n",
              "  102],\n",
              " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " 'labels': [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, -100]}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Defining the model**"
      ],
      "metadata": {
        "id": "OA6epGsI-UUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining model\n",
        "ner_model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=9)"
      ],
      "metadata": {
        "id": "VTJvJnJ_Q3hu",
        "outputId": "4615330d-968b-4cc7-a9c6-f326586caf5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U accelerate\n",
        "! pip install -U transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "id": "vTbkxxPKBVN5",
        "outputId": "d4666eb6-3ff6-4193-9173-8b516a886e7c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Collecting accelerate\n",
            "  Using cached accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.20.3\n",
            "    Uninstalling accelerate-0.20.3:\n",
            "      Successfully uninstalled accelerate-0.20.3\n",
            "Successfully installed accelerate-0.23.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "accelerate"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate>=0.20.1\n",
        "!pip install 'accelerate>=0.20.1,<0.21'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "lPW6ipUWB-mu",
        "outputId": "8af35904-4fd6-4aea-d55b-c99837fbd8d3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate<0.21,>=0.20.1\n",
            "  Using cached accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate<0.21,>=0.20.1) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<0.21,>=0.20.1) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate<0.21,>=0.20.1) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate<0.21,>=0.20.1) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<0.21,>=0.20.1) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate<0.21,>=0.20.1) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate<0.21,>=0.20.1) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate<0.21,>=0.20.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate<0.21,>=0.20.1) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate<0.21,>=0.20.1) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate<0.21,>=0.20.1) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate<0.21,>=0.20.1) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate<0.21,>=0.20.1) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate<0.21,>=0.20.1) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate<0.21,>=0.20.1) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.23.0\n",
            "    Uninstalling accelerate-0.23.0:\n",
            "      Successfully uninstalled accelerate-0.23.0\n",
            "Successfully installed accelerate-0.20.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "accelerate"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import accelerate\n",
        "import transformers\n",
        "\n",
        "transformers.__version__, accelerate.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ5hewXl_-5y",
        "outputId": "3e86d4f9-fbdf-4877-edc4-4bb7b903fc6a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('4.33.3', '0.20.3')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define training args\n",
        "from transformers import TrainingArguments, Trainer\n",
        "args = TrainingArguments(\n",
        "\"test-ner\",\n",
        "evaluation_strategy = \"epoch\",\n",
        "learning_rate=2e-5,\n",
        "per_device_train_batch_size=16,\n",
        "per_device_eval_batch_size=16,\n",
        "num_train_epochs=1,\n",
        "weight_decay=0.01,\n",
        ")\n"
      ],
      "metadata": {
        "id": "Sg67bEBl_0uc"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForTokenClassification(tokenizer)"
      ],
      "metadata": {
        "id": "0bLctsQoDBDA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = datasets.load_metric(\"seqeval\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "b85487cb3cbc4c1da822a0c036b8fdea",
            "2cb94704cf66435b81ff24d2a8fb7b06",
            "f19da5a9934a4603bb25ecc8baef6694",
            "8d03c2eed255421c8f791d05fb99a688",
            "9cc8553f85684cc784904ed5399d3322",
            "0c843dbafcfc4224b4a6adbc7a1dac33",
            "85fd2ee8a6ed43118e85227db73a8c3b",
            "ee8c3e33b24e48dcbea2a9cb8051842b",
            "92e463fd9c784f79bf09f07831e881fa",
            "c7aff299189e42ee8b0b43fcb0a7f85b",
            "fa4f4f84a5f74d90b56176b407717540"
          ]
        },
        "id": "jXRm1FC0DHa9",
        "outputId": "1533f64a-a8fa-403d-bddb-51f698d3f2aa"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-b144b02b338d>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = datasets.load_metric(\"seqeval\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b85487cb3cbc4c1da822a0c036b8fdea"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = ner_data[\"train\"].features[\"ner_tags\"].feature.names\n",
        "label_list\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ-RwQozG6Hj",
        "outputId": "1a8ac4f2-b855-49c2-f6a0-33da20507301"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute Metrics\n",
        "\n",
        "This compute_metrics() function first takes the argmax of the logits to convert them to predictions (as usual, the logits and the probabilities are in the same order, so we don’t need to apply the softmax). Then we have to convert both labels and predictions from integers to strings. We remove all the values where the label is -100, then pass the results to the metric.compute() method:"
      ],
      "metadata": {
        "id": "VegBjEVSGpW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    pred_logits, labels = eval_preds\n",
        "    print(eval_preds)\n",
        "\n",
        "    pred_logits = np.argmax(pred_logits, axis=2)\n",
        "    # the logits and the probabilities are in the same order,\n",
        "    # so we don’t need to apply the softmax\n",
        "\n",
        "    # We remove all the values where the label is -100\n",
        "    predictions = [\n",
        "        [label_list[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(pred_logits, labels)\n",
        "    ]\n",
        "\n",
        "    true_labels = [\n",
        "      [label_list[l] for (eval_preds, l) in zip(prediction, label) if l != -100]\n",
        "       for prediction, label in zip(pred_logits, labels)\n",
        "   ]\n",
        "    results = metric.compute(predictions=predictions, references=true_labels)\n",
        "\n",
        "    return {\n",
        "          \"precision\": results[\"overall_precision\"],\n",
        "          \"recall\": results[\"overall_recall\"],\n",
        "          \"f1\": results[\"overall_f1\"],\n",
        "          \"accuracy\": results[\"overall_accuracy\"],\n",
        "  }"
      ],
      "metadata": {
        "id": "xnHZXoRUGolA"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train the model**"
      ],
      "metadata": {
        "id": "AthC4bjYHoBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "   ner_model,\n",
        "   args,\n",
        "   train_dataset=tokenized_datasets[\"train\"],\n",
        "   eval_dataset=tokenized_datasets[\"validation\"],\n",
        "   data_collator=data_collator,\n",
        "   tokenizer=tokenizer,\n",
        "   compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "d8UI3OCnHrb_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "P7oxkSxAH5AH",
        "outputId": "ce04cfb9-64d5-4b10-9aa9-27ede7f11f86"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='878' max='878' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [878/878 02:39, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.229200</td>\n",
              "      <td>0.072312</td>\n",
              "      <td>0.904428</td>\n",
              "      <td>0.923146</td>\n",
              "      <td>0.913691</td>\n",
              "      <td>0.980444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<transformers.trainer_utils.EvalPrediction object at 0x7c3c0024abc0>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=878, training_loss=0.1671096349903011, metrics={'train_runtime': 162.3257, 'train_samples_per_second': 86.499, 'train_steps_per_second': 5.409, 'total_flos': 342221911376202.0, 'train_loss': 0.1671096349903011, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Save Model**"
      ],
      "metadata": {
        "id": "_89FmP8V0xaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Save model\n",
        "ner_model.save_pretrained(\"ner_model\")"
      ],
      "metadata": {
        "id": "nVxC4F_I00G8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Save tokenizer\n",
        "tokenizer.save_pretrained(\"tokenizer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3GcxDEK09JF",
        "outputId": "eae1ab28-ecbd-444f-adc9-c5e3cf80508a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tokenizer/tokenizer_config.json',\n",
              " 'tokenizer/special_tokens_map.json',\n",
              " 'tokenizer/vocab.txt',\n",
              " 'tokenizer/added_tokens.json',\n",
              " 'tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {\n",
        "    str(i): label for i,label in enumerate(label_list)\n",
        "}\n",
        "label2id = {\n",
        "    label: str(i) for i,label in enumerate(label_list)\n",
        "}"
      ],
      "metadata": {
        "id": "BzW3WumK1EeD"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjnsUP3B1Nxb",
        "outputId": "cdeaf9a2-41b4-4477-e475-695c68cc73cd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 'O',\n",
              " '1': 'B-PER',\n",
              " '2': 'I-PER',\n",
              " '3': 'B-ORG',\n",
              " '4': 'I-ORG',\n",
              " '5': 'B-LOC',\n",
              " '6': 'I-LOC',\n",
              " '7': 'B-MISC',\n",
              " '8': 'I-MISC'}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYYhwQeE1QL5",
        "outputId": "7681d5e6-4f16-4fed-c8c4-2a0eb23887f7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'O': '0',\n",
              " 'B-PER': '1',\n",
              " 'I-PER': '2',\n",
              " 'B-ORG': '3',\n",
              " 'I-ORG': '4',\n",
              " 'B-LOC': '5',\n",
              " 'I-LOC': '6',\n",
              " 'B-MISC': '7',\n",
              " 'I-MISC': '8'}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load model & predicton**"
      ],
      "metadata": {
        "id": "5BhH95zc1lpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "KQCFo4981sJM"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = json.load(open(\"ner_model/config.json\"))\n",
        "config[\"id2label\"] = id2label\n",
        "config[\"label2id\"] = label2id\n",
        "json.dump(config, open(\"ner_model/config.json\",\"w\"))"
      ],
      "metadata": {
        "id": "MHjj2Xqw11pu"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fine_tuned = AutoModelForTokenClassification.from_pretrained(\"ner_model\")\n"
      ],
      "metadata": {
        "id": "lEbj3cqexqxm"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "5hJYTXC7x_j2"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = pipeline(\"ner\",model=model_fine_tuned,tokenizer=tokenizer)\n",
        "example = \"Sundar is a ceo of google and alphabet\"\n",
        "ner_results = nlp(example)\n",
        "print(ner_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMotAseQyE5D",
        "outputId": "eecd7727-7ad5-44c0-f280-4c59e9d8f7ab"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity': 'B-PER', 'score': 0.99158305, 'index': 1, 'word': 'sun', 'start': 0, 'end': 3}, {'entity': 'B-PER', 'score': 0.9922695, 'index': 2, 'word': '##dar', 'start': 3, 'end': 6}, {'entity': 'B-ORG', 'score': 0.96788937, 'index': 7, 'word': 'google', 'start': 19, 'end': 25}, {'entity': 'B-ORG', 'score': 0.98193914, 'index': 9, 'word': 'alphabet', 'start': 30, 'end': 38}]\n"
          ]
        }
      ]
    }
  ]
}